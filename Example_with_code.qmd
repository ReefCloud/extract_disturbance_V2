---
title: "Extract and process disturbance layers"
subtitle: "ReefCloud"
author:
  - name: Julie Vercelloni
    corresponding: true
    email: j.vercelloni@aims.gov.au
  - name: Murray Logan
  - name: Manuel Gonzalez-Rivero
engine: knitr
format:
  html:
   # toc: true
  #  toc-location: left
    title-block-banner: true
    toc-depth: 3
    highlight-style: atom-one
    embed-resources: true
    theme:
      light: flatly
      dark: darkly
    code-overflow: wrap
    code-fold: false
    number-sections: true
    number-depth: 2
    shift-heading-level-by: -1
    crossref:
      lst-title: Code listing
    fig-align: center
    text-align: center
    acm-html: default
# css: styles.css
execute: 
  message: false
  warning: false
  cache: false
  freeze: auto
editor:
  markdown:
    wrap: 72
---

## Introduction 

This vignette provides reproducible R code to extract disturbance data from the ReefCloud server. The processing includes applying time lags and adjusting values based on whether surveys occurred before or after disturbance impacts within a given year.

## R codes

```{r}
#| include: true
#| echo: true
#| eval: true
#| cache: false
rm(list=ls())

# Source packages and functions 
path <- ""
source(paste0(path,"R/packages.R"))
source(paste0(path,"R/functions.R"))
```

```{r}
#| include: true
#| echo: true
#| eval: true
#| cache: false

########################################################################
####################### Get geoserver info 
########################################################################
get_geoserver_info()
```

```{r}
#| include: true
#| echo: true
#| eval: true
#| cache: false
########################################################################
####################### Generate data locations
########################################################################

#Generate sites 
sites<- data.frame(x=c(143.2579, 145.571, 152.3724), y=c(-11.02353, -16.38352, -23.84812)) %>%
  as.matrix() %>%
  st_multipoint() %>% 
  st_sfc(crs=4326) %>% 
  st_cast('POINT') %>%
  st_sf(name=c("Site1", "Site2", "Site3"))

# Generate random years for each site (example: 15 random years per site)
set.seed(123) 
years <- sample(1998:2025, size = 15, replace = FALSE)  # 15 distinct years

# Generate random dates per site
random_dates <- lapply(sites$name, function(site_name) {
  months <- sample(1:12, size = length(years), replace = TRUE)
  days <- sapply(months, function(m) sample(1:days_in_month(ymd(paste0(2000, "-", m, "-01"))), 1))
  data.frame(
    name = site_name,
    year = years,
    date = as.Date(paste(years, months, days, sep = "-"))
  )
}) %>% bind_rows()

# Join with sites and arrange
sites_year <- sites %>%
  right_join(random_dates, by = "name") %>%
  arrange(name, date) %>%
  rename(geometry = ".")
``` 

```{r}
#| include: true
#| echo: true
#| eval: true
#| cache: false

########################################################################
####################### Extract DHW and process 
########################################################################
# Get bounding box from sites
bbox <- st_bbox(sites) %>% st_as_sfc()

sf_use_s2(FALSE)
cov_dhw_full <- get_geoserver_data(cov_name = "reefcloud:degrees_heating_weeks_tier", sites)  %>%
  filter(tier == 4)  %>%
  st_make_valid() %>%
  filter(st_intersects(geometry, bbox, sparse = FALSE)) %>%
  rename(max_dhw = dhwmax,
         end_date = latest)

sf::sf_use_s2(TRUE)
# Find matching years
years <- intersect(unique(sites_year$year), unique(cov_dhw_full$year))

# Loop over each year and spatially join
sites_with_tier <- map_dfr(years, function(y) {
  sites_sub <- sites_year %>% filter(year == y)
  dhw_sub <- cov_dhw_full  %>% filter(year == y)
  
  # Only run join if both subsets are non-empty
  if (nrow(sites_sub) > 0 && nrow(dhw_sub) > 0) {
    st_join(sites_sub, dhw_sub, join = st_within, left = FALSE)
  } else {
    NULL  # skip if empty
  }
})

# safety check
#setequal(sites_with_tier$year.x, sites_with_tier$year.y)

sites_with_tier <- sites_with_tier %>%
 rename(year = year.x) %>%
 dplyr::select(- year.y)

cov_dhw <- add_cov_to_data(data = sites_with_tier, cov = cov_dhw_full, cov_name = "dhw")
glimpse(cov_dhw)
```


```{r}
#| include: true
#| echo: true
#| eval: true
#| cache: false
########################################################################
####################### Extract cyclone and process
########################################################################
sf_use_s2(FALSE)
cov_cyc_full <- get_geoserver_data(cov_name = "reefcloud:storm4m_exposure_year_tier", sites) %>%
  filter(tier == 4) %>%
  st_simplify(dTolerance = 0.001) %>%
  filter(st_intersects(geometry, bbox, sparse = FALSE)) %>%
  rename(max_cyc = max_hrs,
         year = end_year)

sf::sf_use_s2(TRUE)
# Find matching years
years <- intersect(unique(sites_year$year), unique(cov_cyc_full$year))

# Loop over each year and spatially join
sites_with_tier <- map_dfr(years, function(y) {
  sites_sub <- sites_year %>% filter(year == y)
  cyc_sub <- cov_cyc_full  %>% filter(year == y)
  
  # Only run join if both subsets are non-empty
  if (nrow(sites_sub) > 0 && nrow(cyc_sub) > 0) {
    st_join(sites_sub, cyc_sub, join = st_within, left = FALSE)
  } else {
    NULL  # skip if empty
  }
})

# safety check
#setequal(sites_with_tier$year.x, sites_with_tier$year.y)

sites_with_tier <- sites_with_tier %>%
 rename(year = year.x) %>%
 dplyr::select(- year.y)

cov_cyc <- add_cov_to_data(data = sites_with_tier, cov = cov_cyc_full, cov_name = "cyc")
glimpse(cov_cyc)
```